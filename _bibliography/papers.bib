---
---

# Publications

# Preprints

@article{nairoh26arxiv,
  author = {Nair, Sathvik and Oh, Byung-Doh},
  title = {Clozing the gap: Exploring why language model surprisal outperforms cloze surprisal},
  year = {2026},
  journal = {arXiv},
  pdf = {https://arxiv.org/abs/2601.09886},
  abbr = {arXiv},
  section = {preprints},
  bibtex_show = {true}
}

@article{timkeyetal25psyarxiv,
  author = {Timkey, William and Huang, Kuan-Jung and Oh, Byung-Doh and Prasad, Grusha and Arehalli, Suhas and Linzen, Tal and Dillon, Brian},
  title = {Eye movements reveal a dissociation between prediction and structural processing in language comprehension},
  year = {2025},
  journal = {PsyArXiv},
  pdf = {https://osf.io/preprints/psyarxiv/eq2ra_v1},
  abbr = {PsyArXiv},
  section = {preprints},
  bibtex_show = {true}
}

@article{ohlinzen25arxiv,
  author = {Oh, Byung-Doh and Linzen, Tal},
  title = {To model human linguistic prediction, make LLMs less superhuman},
  year = {2025},
  journal = {arXiv},
  pdf = {https://arxiv.org/abs/2510.05141},
  abbr = {arXiv},
  section = {preprints},
  bibtex_show = {true}
}

# 2025

@inproceedings{clarketal25aacl,
  author = {Clark, Christian and Oh, Byung-Doh and Schuler, William},
  title = {How well does first-token entropy approximate word entropy as a psycholinguistic predictor?},
  year = {2025},
  booktitle = {Proceedings of the 14th International Joint Conference on Natural Language Processing and the 4th Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics},
  pages = {47--57},
  pdf = {https://aclanthology.org/2025.ijcnlp-short.4},
  abbr = {AACL},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{ohschuler25acl,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {The impact of token granularity on the predictive power of language model surprisal},
  year = {2025},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics},
  pages = {4150--4162},
  pdf = {https://aclanthology.org/2025.acl-long.209},
  slides = {acl25_tokenizer_slides.pdf},
  abbr = {ACL},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{ohetal25acl,
  author = {Oh, Byung-Doh and Zhu, Hongao and Schuler, William},
  title = {The inverse scaling effect of pre-trained language model surprisal is not due to data leakage},
  year = {2025},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  pages = {1820--1827},
  pdf = {https://aclanthology.org/2025.findings-acl.91},
  slides = {facl25_leakage_pos.pdf},
  abbr = {ACL Findings},
  section = {papers},
  bibtex_show = {true}
}

@article{ohschuler25jml,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {Dissociable frequency effects attenuate as large language model surprisal predictors improve},
  year = {2025},
  journal = {Journal of Memory and Language},
  volume = {143},
  pages = {104645},
  pdf = {https://doi.org/10.1016/j.jml.2025.104645},
  abbr = {JML},
  section = {articles},
  selected = {true},
  bibtex_show = {true}
}

@inproceedings{clarketal25coling,
  author = {Clark, Christian and Oh, Byung-Doh and Schuler, William},
  title = {Linear recency bias during training improves Transformers' fit to reading times},
  year = {2025},
  booktitle = {Proceedings of the 31st International Conference on Computational Linguistics},
  pages = {7735-7747},
  pdf = {https://aclanthology.org/2025.coling-main.517},
  abbr = {COLING},
  section = {papers},
  bibtex_show = {true}
}

# 2024

@inproceedings{ohschuler24emnlp,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {Leading whitespaces of language models' subword vocabulary pose a confound for calculating word probabilities},
  year = {2024},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages = {3464--3472},
  pdf = {https://aclanthology.org/2024.emnlp-main.202},
  poster = {emnlp24_whitespace_pos.pdf},
  abbr = {EMNLP},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{ohetal24eacl,
  author = {Oh, Byung-Doh and Yue, Shisen and Schuler, William},
  title = {Frequency explains the inverse correlation of large language models' size, training data amount, and surprisal's fit to reading times},
  year = {2024},
  booktitle = {Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics},
  pages = {2644--2663},
  pdf = {https://aclanthology.org/2024.eacl-long.162},
  slides = {eacl24_frequency_slides.pdf},
  abbr = {EACL},
  section = {papers},
  selected = {true},
  bibtex_show = {true}
}

# 2023

@inproceedings{ohschuler23emnlp,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {Transformer-based language model surprisal predicts human reading times best with about two billion training tokens},
  year = {2023},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages = {1915--1921},
  pdf = {https://aclanthology.org/2023.findings-emnlp.128},
  slides = {femnlp23_slmsurp_slides.pdf},
  abbr = {EMNLP Findings},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{ohschuler23acl,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {Token-wise decomposition of autoregressive language model hidden states for analyzing model predictions},
  year = {2023},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics},
  pages = {10105--10117},
  pdf = {https://aclanthology.org/2023.acl-long.562},
  poster = {acl23_decomp_pos.pdf},
  abbr = {ACL},
  section = {papers},
  selected = {true},
  bibtex_show = {true}
}

@article{ohschuler23tacl,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {Why does surprisal from larger Transformer-based language models provide a poorer fit to human reading times?},
  year = {2023},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {11},
  pages = {336--350},
  pdf = {https://doi.org/10.1162/tacl_a_00548},
  slides = {tacl23_surpinv_slides.pdf},
  abbr = {TACL},
  section = {articles},
  selected = {true},
  bibtex_show = {true}
}

# 2022

@inproceedings{ohschuler22emnlp,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {Entropy- and distance-based predictors from GPT-2 attention patterns predict reading times over and above GPT-2 surprisal},
  year = {2022},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages = {9324--9334},
  pdf = {https://aclanthology.org/2022.emnlp-main.632},
  poster = {emnlp22_attndist_pos.pdf},
  abbr = {EMNLP},
  section = {papers},
  selected = {true},
  bibtex_show = {true}
}

@article{ohetal22fai,
  author = {Oh, Byung-Doh and Clark, Christian and Schuler, William},
  title = {Comparison of structural parsers and neural language models as surprisal estimators},
  year = {2022},
  journal = {Frontiers in Artificial Intelligence},
  volume = {5},
  pages = {777963},
  pdf = {https://doi.org/10.3389/frai.2022.777963},
  abbr = {FAI},
  section = {articles},
  selected = {true},
  bibtex_show = {true}
}

# 2021

@inproceedings{jinetal21emnlp,
  author = {Jin, Lifeng and Oh, Byung-Doh and Schuler, William},
  title = {Character-based PCFG induction for modeling the syntactic acquisition of morphologically rich languages},
  year = {2021},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages = {4367--4378},
  pdf = {https://aclanthology.org/2021.findings-emnlp.371},
  abbr = {EMNLP Findings},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{jaffeetal21emnlp,
  author = {Jaffe, Evan and Oh, Byung-Doh and Schuler, William},
  title = {Coreference-aware surprisal predicts brain response},
  year = {2021},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages = {3351--3356},
  pdf = {https://aclanthology.org/2021.findings-emnlp.285},
  abbr = {EMNLP Findings},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{ohetal21acl,
  author = {Oh, Byung-Doh and Clark, Christian and Schuler, William},
  title = {Surprisal estimators for human reading times need character models},
  year = {2021},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing},
  pages = {3746--3757},
  pdf = {https://aclanthology.org/2021.acl-long.290},
  slides = {acl21_semproc_slides.pdf},
  abbr = {ACL},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{ohschuler21cmcl,
  author = {Oh, Byung-Doh and Schuler, William},
  title = {Contributions of propositional content and syntactic category information in sentence processing},
  year = {2021},
  booktitle = {Proceedings of the 11th Workshop on Cognitive Modeling and Computational Linguistics},
  pages = {241--250},
  pdf = {https://aclanthology.org/2021.cmcl-1.28},
  poster = {cmcl21_catcon_pos.pdf},
  abbr = {CMCL},
  section = {papers},
  bibtex_show = {true}
}

@inproceedings{oh21cmcl,
  author = {Oh, Byung-Doh},
  title = {Team Ohio State at CMCL 2021 shared task: Fine-tuned RoBERTa for eye-tracking data prediction},
  year = {2021},
  booktitle = {Proceedings of the 11th Workshop on Cognitive Modeling and Computational Linguistics},
  pages = {97-101},
  pdf = {https://aclanthology.org/2021.cmcl-1.11},
  poster = {cmcl21_st_pos.pdf},
  abbr = {CMCL},
  section = {papers},
  bibtex_show = {true}
}

# 2019

@inproceedings{ohetal19sigmorphon,
  author = {Oh, Byung-Doh and Maneriker, Pranav and Jiang, Nanjiang},
  title = {THOMAS: The hegemonic OSU morphological analyzer using seq2seq},
  year = {2019},
  booktitle = {Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology},
  pages = {80--86},
  pdf = {https://aclanthology.org/W19-4210},
  abbr = {SIGMORPHON},
  section = {abstracts},
  bibtex_show = {true}
}

@article{elsneretal19jlm,
  author = {Elsner, Micha and Sims, Andrea D. and Erdmann, Alexander and Hernandez, Antonio and Jaffe, Evan and Jin, Lifeng and Johnson, Martha Booker and Karim, Shuan and King, David L. and Lamberti Nunes, Luana and Oh, Byung-Doh and Rasmussen, Nathan and Shain, Cory and Antetomaso, Stephanie and Dickinson, Kendra V. and Diewald, Noah and McKenzie, Michelle and Stevens-Guille, Symon},
  title = {Modeling morphological learning, typology, and change: What can the neural sequence-to-sequence framework contribute?},
  year = {2019},
  journal = {Journal of Language Modelling},
  volume = {7},
  number = {1},
  pages = {53--98},
  pdf = {https://doi.org/10.15398/jlm.v7i1.244},
  abbr = {JLM},
  section = {articles},
  bibtex_show = {true}
}

# 2018

@article{ohso18et,
  author = {Oh, Byung-Doh and So, Youngsoon},
  title = {Exploring English online research and comprehension strategies of Korean college students},
  year = {2018},
  journal = {English Teaching},
  volume = {73},
  number = {3},
  pages = {53--76},
  pdf = {https://doi.org/10.15858/engtea.73.3.201809.53},
  abbr = {Eng Tea},
  section = {articles},
  bibtex_show = {true}
}

# 2017

@article{oh17fler,
  author = {Oh, Byung-Doh},
  title = {Predicting L2 writing proficiency with computational indices based on n-grams},
  year = {2017},
  journal = {Foreign Language Education Research},
  volume = {21},
  pages = {1-20},
  pdf = {https://hdl.handle.net/10371/139753},
  abbr = {FLER},
  section = {articles},
  bibtex_show = {true}
}

# Talks

@article{stanford25,
    title = {Language model surprisal does not underpredict garden path effects in early eye-tracking measures},
    journal = {Laboratory for Computation and Language in Minds and Brains, Stanford University (Online)},
    year = {2025},
    slides = {stanford_251031.pdf},
    abbr = {Talk},
    section = {talks}
}

@article{ntu25,
    title = {Unveiling the language processing of humans and machines},
    journal = {Linguistics and Multilingual Studies, Nanyang Technological University},
    year = {2025},
    abbr = {Talk},
    section = {talks}
}

@article{postech24,
    title = {What can linguistic data tell us about the predictions of large language models?},
    journal = {Department of Computer Science/Graduate School of AI, POSTECH},
    year = {2024},
    slides = {postech_241007.pdf},
    abbr = {Talk},
    section = {talks}
}

@article{uds24,
    title = {The bigger-is-worse effects of model size and training data of large language model surprisal on human reading times},
    journal = {Distinguished Speakers in Language Science Colloquium Series, Saarland University},
    year = {2024},
    slides = {uds_240425.pdf},
    abbr = {Talk},
    section = {talks}
}

@article{nyu23,
    title = {The bigger-is-worse effects of model size and training data of large language model surprisal on human reading times},
    journal = {Computation and Psycholinguistics Lab, New York University},
    year = {2023},
    slides = {nyu_231109.pdf},
    abbr = {Talk},
    section = {talks}
}

@article{du22,
    title = {Computational models of sentence processing and syntactic acquisition},
    journal = {Department of English, Dongguk University (Online)},
    year = {2022},
    slides = {du_220214.pdf},
    abbr = {Talk},
    section = {talks}
}

# Teaching

@article{psycholing26,
    title = {HG4015/7015},
    journal = {Instructor of Record, Nanyang Technological University, Spring},
    year = {2026},
    abbr = {Teaching},
    section = {teaching}
}

@article{capstone25,
    title = {DS-GA 1006: Capstone Project and Presentation},
    journal = {Instructor of Record (with Aahlad Puli and Shauli Ravfogel), New York University, Autumn},
    year = {2025},
    website = {https://cds.nyu.edu/masters-in-data-science-capstone},
    abbr = {Teaching},
    section = {teaching}
}

@article{nlu25,
    title = {Unveiling the language processing of humans (and machines)},
    journal = {Guest Lecture, Natural Language Understanding and Computational Semantics, New York University (Instructor: Tal Linzen)},
    year = {2025},
    slides = {nlu_250425.pdf},
    abbr = {Teaching},
    section = {teaching}
}

@article{latc25,
    title = {Treating text documents like pizza},
    journal = {Guest Lecture, Language and the Computer, Nanyang Technological University (Instructor: Hiram Ring)},
    year = {2025},
    abbr = {Teaching},
    section = {teaching}
}

@article{textasdata25,
    title = {DS-GA 1015: Text as Data},
    journal = {Instructor of Record, New York University, Spring},
    year = {2025},
    syllabus = {sp25_textasdata.pdf},
    abbr = {Teaching},
    section = {teaching}
}

@article{clcs24,
    title = {Transformer-based language model surprisal predicts human reading times best with about two billion training tokens},
    journal = {Guest Lecture, Computational Linguistics and Cognitive Science, New York University (Instructor: Tal Linzen)},
    year = {2024},
    abbr = {Teaching},
    section = {teaching}
}

@article{metro24,
    title = {Guessing meaning and breaking it down (with NACLO problems)},
    journal = {Guest Lecture, Metro Early College High School},
    year = {2024},
    slides = {metro_240124.pdf},
    abbr = {Teaching},
    section = {teaching}
}

@article{codebreaking21,
    title = {LING 3801: Codes and Code Breaking},
    journal = {Instructor of Record, The Ohio State University, Spring},
    year = {2021},
    syllabus = {sp21_codebreaking.pdf},
    abbr = {Teaching},
    section = {teaching}
}

@article{codebreaking20,
    title = {LING 3801: Codes and Code Breaking},
    journal = {Instructor of Record, The Ohio State University, Autumn},
    year = {2020},
    syllabus = {au20_codebreaking.pdf},
    abbr = {Teaching},
    section = {teaching}
}

@article{colenglish17,
    title = {College English 1},
    journal = {Teaching Assistant, Seoul National University, Summer},
    year = {2017},
    abbr = {Teaching},
    section = {teaching}
}
